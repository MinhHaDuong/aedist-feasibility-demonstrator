"""Convert experiment results to LaTeX tables and macros.

Usage:
    python src/convert.py --output inputs/generated/
    python src/convert.py --output inputs/generated/ --date 2025-01-28

Generates:
    macros.tex         - \newcommand definitions for inline numbers
    tab_relances.tex   - Table: LLM results with follow-up prompts
    tab_comparaison.tex - Table: with vs without source documents
"""

import argparse
import csv
import io
import json
from pathlib import Path


# ---------------------------------------------------------------------------
# Result loading
# ---------------------------------------------------------------------------

def find_latest_run(results_dir: Path) -> Path | None:
    """Find the most recent dated subdirectory in a results folder."""
    if not results_dir.exists():
        return None
    dated_dirs = sorted(
        [d for d in results_dir.iterdir() if d.is_dir() and d.name[:4].isdigit()],
        key=lambda d: d.name,
    )
    return dated_dirs[-1] if dated_dirs else None


def load_results(results_dir: Path, run_date: str | None = None) -> dict[str, dict]:
    """Load all JSON result files from a run. Returns {model_slug: record}."""
    if run_date:
        run_dir = results_dir / run_date
    else:
        run_dir = find_latest_run(results_dir)

    if run_dir is None or not run_dir.exists():
        return {}

    results = {}
    for f in sorted(run_dir.glob("*.json")):
        with open(f) as fh:
            record = json.load(fh)
        slug = f.stem  # e.g. "claude-3.5-sonnet"
        results[slug] = record
    return results


# ---------------------------------------------------------------------------
# Response parsing
# ---------------------------------------------------------------------------

def count_csv_rows(response_text: str) -> int:
    """Count data rows in a CSV response (excluding header)."""
    if not response_text:
        return 0
    # Find the CSV block: look for lines with commas that form a table
    lines = response_text.strip().split("\n")
    csv_lines = []
    in_csv = False
    for line in lines:
        stripped = line.strip()
        # Detect CSV start: line with multiple commas or starts with quote
        if not in_csv and stripped.count(",") >= 2:
            in_csv = True
        if in_csv:
            if stripped == "" or stripped.startswith("```"):
                if csv_lines:
                    break
                continue
            csv_lines.append(stripped)

    if len(csv_lines) < 2:
        return 0

    # Parse to count valid data rows
    try:
        reader = csv.reader(io.StringIO("\n".join(csv_lines)))
        rows = list(reader)
        return len(rows) - 1  # subtract header
    except csv.Error:
        return len(csv_lines) - 1


# ---------------------------------------------------------------------------
# Macros generation
# ---------------------------------------------------------------------------

# Fallback values from the current report (used when results aren't available)
EXPERIMENT1_FALLBACKS = {
    "SimplyAskDeepSeek": 64,
    "SimplyAskGeminiFlash": 41,
    "SimplyAskClaudeSonnet": 38,
    "SimplyAskGPTFourO": 33,
    "SimplyAskPerplexityPro": 22,
    "SimplyAskLlama": 18,
}

# Map from result file slug to macro name
EXPERIMENT1_MACRO_MAP = {
    "deepseek-r1": "SimplyAskDeepSeek",
    "gemini-2.0-flash-001": "SimplyAskGeminiFlash",
    "claude-3.5-sonnet": "SimplyAskClaudeSonnet",
    "gpt-4o": "SimplyAskGPTFourO",
    "sonar-pro": "SimplyAskPerplexityPro",
    "llama-3.3-70b-instruct": "SimplyAskLlama",
}


def generate_macros(exp1_results: dict[str, dict]) -> str:
    """Generate LaTeX \\newcommand definitions for inline numbers."""
    values = dict(EXPERIMENT1_FALLBACKS)

    # Override with actual results where available
    for slug, record in exp1_results.items():
        macro_name = EXPERIMENT1_MACRO_MAP.get(slug)
        if macro_name and record.get("response"):
            count = count_csv_rows(record["response"])
            if count > 0:
                values[macro_name] = count

    lines = ["% Auto-generated by src/convert.py — do not edit",
             "% Experiment 1: Simply ask"]
    for name, value in values.items():
        lines.append(f"\\newcommand{{\\{name}}}{{{value}}}")

    return "\n".join(lines) + "\n"


# ---------------------------------------------------------------------------
# Table: tab_relances
# ---------------------------------------------------------------------------

# Hardcoded data from report lines 244-250.
# Columns: label, prompt1, relance1, relance2, relance3, relance4
# As experiments are automated, prompt1 becomes data-driven (Exp 1),
# relance columns become data-driven (Exp 2).
TAB_RELANCES_DATA = [
    ("Claude 3.5 Sonnet", "34", "24", "50", "73", "+14 = 87"),
    ("DeepSeek (COT off, Search off)", "10", "24", "48", "70", "80"),
    ("GPT-4o (on Poe)", "25", "36", "50", "60+", "70+"),
    ("Llama 3.3 70B (on Poe)", "32", "18", "44", "bloque", "n/a"),
    ("Qwen 2.5 72B T (on Poe)", "19", "36", "bloque", "", ""),
    ("o3-mini (medium)", "12", "7", "14", "25", "=c'est possible"),
    ("o3-mini (high)", "15", "8", "19", "25", "=Potentially"),
]


def generate_tab_relances(exp1_results: dict[str, dict]) -> str:
    """Generate the tab:relances longtable."""
    rows = []
    for label, p1, r1, r2, r3, r4 in TAB_RELANCES_DATA:
        # TODO: override p1 from exp1_results when Experiment 1 is re-run
        # TODO: override r1-r4 from exp2_results when Experiment 2 is automated
        rows.append(f"{label} & {p1} & {r1} & {r2} & {r3} & {r4} \\\\")

    return (
        "% Auto-generated by src/convert.py — do not edit\n"
        "\\begin{longtable}[]{@{}llllll@{}}\n"
        "\\caption{Évolution du nombre de centrales thermiques identifiées "
        "par les modèles de langage après relances "
        "successives.}\\label{tab:relances}\\\\\n"
        "\\toprule\\noalign{}\n"
        "Modèle & Prompt 1 & Relance 1 & Relance 2 & Relance 3 & Relance 4 \\\\\n"
        "\\midrule\\noalign{}\n"
        "\\endhead\n"
        "\\bottomrule\\noalign{}\n"
        "\\endlastfoot\n"
        + "\n".join(rows) + "\n"
        "\\end{longtable}\n"
    )


# ---------------------------------------------------------------------------
# Table: tab_comparaison
# ---------------------------------------------------------------------------

# Hardcoded data from report lines 530-557.
# As experiments are automated, "sans" becomes data-driven (Exp 1),
# "avec" becomes data-driven (Exp 3 / RAG).
TAB_COMPARAISON_DATA = [
    ("Claude 3.5 Sonnet", "63", "\\tnote{a,b}"),
    ("DeepSeek-R1 (on Poe)", "40", "65"),
    ("GPT-4o (on Poe)", "\\tnote{c,cc} puis 33", "49"),
    ("o1-mini (on Poe)", "37\\tnote{c,e}", "39\\tnote{c,f}"),
    ("o3-mini medium", "32\\tnote{g}", "41"),
    ("o3-mini high", "39\\tnote{g}", "78"),
]

TAB_COMPARAISON_NOTES = [
    ("a", "Liste les Units et non les Plants."),
    ("b", "Stoppé par limite."),
    ("c", "Liste l'hydroélectricité."),
    ("cc", "La relance est «~Thermal power is coal, gas and oil~»."),
    ("d", "Stoppé limite RPD."),
    ("e", "Includes a nonsense line at the end about thermal renewable."),
    ("f", "Se limite aux projets opérationnels."),
    ("g", "Source himself instead of from the provided docs."),
]


def generate_tab_comparaison(exp1_results: dict[str, dict]) -> str:
    """Generate the tab:comparaison ThreePartTable."""
    notes = "\n".join(
        f"\\item[{key}] {text}" for key, text in TAB_COMPARAISON_NOTES
    )
    rows = []
    for label, sans, avec in TAB_COMPARAISON_DATA:
        # TODO: override sans from exp1_results when Experiment 1 is re-run
        # TODO: override avec from exp3_results when Experiment 3 is automated
        rows.append(f"{label} & {sans} & {avec} \\\\")

    return (
        "% Auto-generated by src/convert.py — do not edit\n"
        "\\begin{ThreePartTable}\n"
        "\\begin{TableNotes}[flushleft]\\footnotesize\n"
        + notes + "\n"
        "\\end{TableNotes}\n"
        "\\begin{longtable}[]{@{}lll@{}}\n"
        "\\caption{Comparaison du nombre de centrales thermiques vietnamiennes "
        "identifiées par différents modèles, avec et sans documents sources, "
        "janvier-février 2025}\\label{tab:comparaison}\\\\\n"
        "\\toprule\n"
        "Modèle & Sans documents & Avec documents \\\\\n"
        "\\midrule\n"
        "\\endhead\n"
        "\\bottomrule\n"
        "\\insertTableNotes\\\\\n"
        "\\endlastfoot\n"
        + "\n".join(rows) + "\n"
        "\\end{longtable}\n"
        "\\end{ThreePartTable}\n"
    )


# ---------------------------------------------------------------------------
# Main
# ---------------------------------------------------------------------------

def main():
    parser = argparse.ArgumentParser(
        description="Convert experiment results to LaTeX"
    )
    parser.add_argument("--output", required=True, help="Output directory")
    parser.add_argument("--date", help="Use results from this date (YYYY-MM-DD)")
    args = parser.parse_args()

    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)

    base = Path("Results")

    # Load available results
    exp1_results = load_results(base / "1_simply_ask", args.date)

    # Generate macros
    macros_path = output_dir / "macros.tex"
    macros_path.write_text(generate_macros(exp1_results))
    print(f"Wrote {macros_path}")

    # Generate tables
    tab_path = output_dir / "tab_relances.tex"
    tab_path.write_text(generate_tab_relances(exp1_results))
    print(f"Wrote {tab_path}")

    tab_path = output_dir / "tab_comparaison.tex"
    tab_path.write_text(generate_tab_comparaison(exp1_results))
    print(f"Wrote {tab_path}")


if __name__ == "__main__":
    main()
